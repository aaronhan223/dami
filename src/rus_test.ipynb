{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "from scipy.special import rel_entr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_Q_new(P: np.ndarray):\n",
    "  '''\n",
    "  Compute optimal Q given 3d array P \n",
    "  with dimensions coressponding to x1, x2, and y respectively\n",
    "  '''\n",
    "  Py = P.sum(axis=0).sum(axis=0)\n",
    "  Px1 = P.sum(axis=1).sum(axis=1)\n",
    "  Px2 = P.sum(axis=0).sum(axis=1)\n",
    "  Px2y = P.sum(axis=0)\n",
    "  Px1y = P.sum(axis=1)\n",
    "  Px1y_given_x2 = P/P.sum(axis=(0,2),keepdims=True)\n",
    " \n",
    "  Q = [cp.Variable((P.shape[0], P.shape[1]), nonneg=True) for i in range(P.shape[2])]\n",
    "  Q_x1x2 = [cp.Variable((P.shape[0], P.shape[1]), nonneg=True) for i in range(P.shape[2])]\n",
    "\n",
    "  # Constraints that conditional distributions sum to 1\n",
    "  sum_to_one_Q = cp.sum([cp.sum(q) for q in Q]) == 1\n",
    "\n",
    "  # Brute force constraints # \n",
    "  # [A]: p(x1, y) == q(x1, y) \n",
    "  # [B]: p(x2, y) == q(x2, y)\n",
    "\n",
    "  # Adding [A] constraints\n",
    "  A_cstrs = []\n",
    "  for x1 in range(P.shape[0]):\n",
    "      for y in range(P.shape[2]):\n",
    "        vars = []\n",
    "        for x2 in range(P.shape[1]):\n",
    "          vars.append(Q[y][x1, x2])\n",
    "        A_cstrs.append(cp.sum(vars) == Px1y[x1,y])\n",
    "  \n",
    "  # Adding [B] constraints\n",
    "  B_cstrs = []\n",
    "  for x2 in range(P.shape[1]):\n",
    "      for y in range(P.shape[2]):\n",
    "        vars = []\n",
    "        for x1 in range(P.shape[0]):\n",
    "          vars.append(Q[y][x1, x2])\n",
    "        B_cstrs.append(cp.sum(vars) == Px2y[x2,y])\n",
    "\n",
    "  # KL divergence\n",
    "  Q_pdt_dist_cstrs = [cp.sum(Q) / P.shape[2] == Q_x1x2[i] for i in range(P.shape[2])]\n",
    "\n",
    "\n",
    "  # objective\n",
    "  obj = cp.sum([cp.sum(cp.rel_entr(Q[i], Q_x1x2[i])) for i in range(P.shape[2])])\n",
    "  # print(obj.shape)\n",
    "  all_constrs = [sum_to_one_Q] + A_cstrs + B_cstrs + Q_pdt_dist_cstrs\n",
    "  prob = cp.Problem(cp.Minimize(obj), all_constrs)\n",
    "  prob.solve(verbose=False, max_iter=50000)\n",
    "\n",
    "  # print(prob.status)\n",
    "  # print(prob.value)\n",
    "  # for j in range(P.shape[1]):\n",
    "  #  print(Q[j].value)\n",
    "\n",
    "  return np.stack([q.value for q in Q],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_binary_data(num_data):\n",
    "  # 00  0\n",
    "  # 01  0\n",
    "  # 10  0\n",
    "  # 11  1\n",
    "\n",
    "  x1 = np.random.randint(0, 2, (num_data, 1))\n",
    "  x2 = np.random.randint(0, 2, (num_data, 1))\n",
    "  data = {\n",
    "      'and': (x1, x2, 1 * np.logical_and(x1, x2)),\n",
    "      'or': (x1, x2, 1 * np.logical_or(x1, x2)),\n",
    "      'xor': (x1, x2, 1 * np.logical_xor(x1, x2)),\n",
    "      'unique1': (x1, x2, x1),\n",
    "      'redundant': (x1, x1, x1),\n",
    "      'redundant_and_unique1': (np.concatenate([x1, x2], axis=1), x2, 1 * np.logical_and(x1, x2)),\n",
    "      'redundant_or_unique1': (np.concatenate([x1, x2], axis=1), x2, 1 * np.logical_or(x1, x2)),\n",
    "      'redundant_xor_unique1': (np.concatenate([x1, x2], axis=1), x2, 1 * np.logical_xor(x1, x2)),\n",
    "  }\n",
    "  return data\n",
    "\n",
    "def convert_data_to_distribution(x1: np.ndarray, x2: np.ndarray, y: np.ndarray):\n",
    "  assert x1.size == x2.size\n",
    "  assert x1.size == y.size\n",
    "\n",
    "  numel = x1.size\n",
    "  \n",
    "  x1_discrete, x1_raw_to_discrete = extract_categorical_from_data(x1.squeeze())\n",
    "  x2_discrete, x2_raw_to_discrete = extract_categorical_from_data(x2.squeeze())\n",
    "  y_discrete, y_raw_to_discrete = extract_categorical_from_data(y.squeeze())\n",
    "\n",
    "  joint_distribution = np.zeros((len(x1_raw_to_discrete), len(x2_raw_to_discrete), len(y_raw_to_discrete)))\n",
    "  for i in range(numel):\n",
    "    joint_distribution[x1_discrete[i], x2_discrete[i], y_discrete[i]] += 1\n",
    "  joint_distribution /= np.sum(joint_distribution)\n",
    "\n",
    "  return joint_distribution, (x1_raw_to_discrete, x2_raw_to_discrete, y_raw_to_discrete)\n",
    "\n",
    "def extract_categorical_from_data(x):\n",
    "  supp = set(x)\n",
    "  raw_to_discrete = dict()\n",
    "  for i in supp:\n",
    "    raw_to_discrete[i] = len(raw_to_discrete)\n",
    "  discrete_data = [raw_to_discrete[x_] for x_ in x]\n",
    "\n",
    "  return discrete_data, raw_to_discrete \n",
    "\n",
    "def MI(P: np.ndarray):\n",
    "  ''' P has 2 dimensions '''\n",
    "  margin_1 = P.sum(axis=1)\n",
    "  margin_2 = P.sum(axis=0)\n",
    "  outer = np.outer(margin_1, margin_2)\n",
    "\n",
    "  return np.sum(rel_entr(P, outer))\n",
    "  # return np.sum(P * np.log(P/outer))\n",
    "\n",
    "def CoI(P:np.ndarray):\n",
    "  ''' P has 3 dimensions, in order X1, X2, Y '''\n",
    "  # MI(Y; X1)\n",
    "  A = P.sum(axis=1)\n",
    "\n",
    "  # MI(Y; X2)\n",
    "  B = P.sum(axis=0)\n",
    "\n",
    "  # MI(Y; (X1, X2))\n",
    "  C = P.transpose([2, 0, 1]).reshape((P.shape[2], P.shape[0]*P.shape[1]))\n",
    "\n",
    "  return MI(A) + MI(B) - MI(C)\n",
    "\n",
    "def CI(P, Q):\n",
    "  assert P.shape == Q.shape\n",
    "  P_ = P.transpose([2, 0, 1]).reshape((P.shape[2], P.shape[0]*P.shape[1]))\n",
    "  Q_ = Q.transpose([2, 0, 1]).reshape((Q.shape[2], Q.shape[0]*Q.shape[1]))\n",
    "  return MI(P_) - MI(Q_)\n",
    "\n",
    "def UI(P, cond_id=0):\n",
    "  ''' P has 3 dimensions, in order X1, X2, Y \n",
    "  We condition on X1 if cond_id = 0, if 1, then X2.\n",
    "  '''\n",
    "  sum = 0.\n",
    "\n",
    "  if cond_id == 0:\n",
    "    J= P.sum(axis=(1,2)) # marginal of x1\n",
    "    for i in range(P.shape[0]):\n",
    "      sum += MI(P[i,:,:]/P[i,:,:].sum()) * J[i]\n",
    "  elif cond_id == 1:\n",
    "    J= P.sum(axis=(0,2)) # marginal of x1\n",
    "    for i in range(P.shape[1]):\n",
    "      sum += MI(P[:,i,:]/P[:,i,:].sum()) * J[i]\n",
    "  else:\n",
    "    assert False\n",
    "\n",
    "  return sum\n",
    "\n",
    "def test(P):\n",
    "  Q = solve_Q_new(P)\n",
    "  redundancy = CoI(Q)\n",
    "  print('Redundancy', redundancy)\n",
    "  unique_1 = UI(Q, cond_id=1)\n",
    "  print('Unique', unique_1)\n",
    "  unique_2 = UI(Q, cond_id=0)\n",
    "  print('Unique', unique_2)\n",
    "  synergy = CI(P, Q)\n",
    "  print('Synergy', synergy)\n",
    "  return {'redundancy':redundancy, 'unique1':unique_1, 'unique2':unique_2, 'synergy':synergy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundancy 3.3705091871802423e-09\n",
      "Unique 1.1187109610023148e-16\n",
      "Unique 1.1187109610023148e-16\n",
      "Synergy 0.6931471771894356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'redundancy': np.float64(3.3705091871802423e-09),\n",
       " 'unique1': np.float64(1.1187109610023148e-16),\n",
       " 'unique2': np.float64(1.1187109610023148e-16),\n",
       " 'synergy': np.float64(0.6931471771894356)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.zeros((2,2,2))\n",
    "P[:,:,0] = np.eye(2) * 0.25\n",
    "P[:,:,1] = np.array([[0., 0.25], [0.25, 0.]])\n",
    "test(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.25, 0.  ],\n",
       "        [0.  , 0.25]],\n",
       "\n",
       "       [[0.  , 0.25],\n",
       "        [0.25, 0.  ]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundancy 9.98812088620106e-06\n",
      "Unique 2.2337941696321481e-10\n",
      "Unique 1.0791333733425263e-05\n",
      "Synergy 0.6931253926816073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'redundancy': np.float64(9.98812088620106e-06),\n",
       " 'unique1': np.float64(2.2337941696321481e-10),\n",
       " 'unique2': np.float64(1.0791333733425263e-05),\n",
       " 'synergy': np.float64(0.6931253926816073)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = gen_binary_data(100000)\n",
    "P, maps = convert_data_to_distribution(*data['xor'])\n",
    "test(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundancy 0.2150743943150804\n",
      "Unique 1.169119897466959e-08\n",
      "Unique 0.0004256690572395108\n",
      "Synergy 0.3458022230173096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'redundancy': np.float64(0.2150743943150804),\n",
       " 'unique1': np.float64(1.169119897466959e-08),\n",
       " 'unique2': np.float64(0.0004256690572395108),\n",
       " 'synergy': np.float64(0.3458022230173096)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = gen_binary_data(1000000)\n",
    "P, maps = convert_data_to_distribution(*data['and'])\n",
    "test(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundancy 0.005723754879699304\n",
      "Unique 0.001233640614499781\n",
      "Unique 0.028903272546529815\n",
      "Synergy 0.07845121016645373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'redundancy': np.float64(0.005723754879699304),\n",
       " 'unique1': np.float64(0.001233640614499781),\n",
       " 'unique2': np.float64(0.028903272546529815),\n",
       " 'synergy': np.float64(0.07845121016645373)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.random.uniform(size=(5,4,3))\n",
    "P = P / np.sum(P)\n",
    "test(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundancy 0.2157615011398003\n",
      "Unique 2.9101687188058173e-08\n",
      "Unique 2.9101687186610088e-08\n",
      "Synergy 0.34657358527563387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'redundancy': np.float64(0.2157615011398003),\n",
       " 'unique1': np.float64(2.9101687188058173e-08),\n",
       " 'unique2': np.float64(2.9101687186610088e-08),\n",
       " 'synergy': np.float64(0.34657358527563387)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HR_flag = np.array([1, 0, 1, 0])    # 1=HR high, 0=normal\n",
    "BP_flag = np.array([1, 1, 0, 0])    # 1=BP low, 0=normal\n",
    "Event   = np.array([1, 0, 0, 0])    # 1=shock event, 0=no event\n",
    "data = (BP_flag, HR_flag, Event)\n",
    "P, maps = convert_data_to_distribution(*data)\n",
    "test(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundancy 0.2157615011398003\n",
      "Unique 2.9101687188058173e-08\n",
      "Unique 2.9101687186610088e-08\n",
      "Synergy 0.34657358527563387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'redundancy': np.float64(0.2157615011398003),\n",
       " 'unique1': np.float64(2.9101687188058173e-08),\n",
       " 'unique2': np.float64(2.9101687186610088e-08),\n",
       " 'synergy': np.float64(0.34657358527563387)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HR_flag = np.array([1, 0, 1, 0])    # 1=HR high, 0=normal\n",
    "BP_flag = np.array([1, 1, 0, 0])    # 1=BP low, 0=normal\n",
    "Event   = np.array([1, 0, 0, 0])    # 1=shock event, 0=no event\n",
    "data = (HR_flag, BP_flag, Event)\n",
    "P, maps = convert_data_to_distribution(*data)\n",
    "test(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dami",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
