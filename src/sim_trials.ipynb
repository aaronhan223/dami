{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICU Multimodal Patient Monitoring: Static PID vs Temporal Directed Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I(HR;Y) = 0.311 bits, I(BP;Y) = 0.311 bits\n",
      "I(HR,BP;Y) = 0.811 bits\n",
      "Redundancy = 0.311, Unique(HR) = 0.000, Unique(BP) = 0.000, Synergy = 0.500\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Binary flags for HR, BP, and event from the scenario table\n",
    "HR_flag = [1, 0, 1, 0]    # 1=HR high, 0=normal\n",
    "BP_flag = [1, 1, 0, 0]    # 1=BP low, 0=normal\n",
    "Event   = [1, 0, 0, 0]    # 1=shock event, 0=no event\n",
    "\n",
    "# Mutual information (in bits) for single modalities and joint:\n",
    "I_hr_y  = mutual_info_score(HR_flag, Event) / math.log(2)      # I(HR; Y)\n",
    "I_bp_y  = mutual_info_score(BP_flag, Event) / math.log(2)      # I(BP; Y)\n",
    "joint_state = [f\"{h}{b}\" for h,b in zip(HR_flag, BP_flag)]     # joint state of (HR,BP)\n",
    "I_hrbp_y = mutual_info_score(joint_state, Event) / math.log(2) # I([HR,BP]; Y)\n",
    "\n",
    "# PID decomposition (Williams & Beer 2010 using I_min redundancy)\n",
    "I_red   = min(I_hr_y, I_bp_y)                        # redundant info\n",
    "U_hr    = I_hr_y - I_red                             # HR unique info\n",
    "U_bp    = I_bp_y - I_red                             # BP unique info\n",
    "S       = I_hrbp_y - I_hr_y - I_bp_y + I_red         # synergistic info\n",
    "\n",
    "print(f\"I(HR;Y) = {I_hr_y:.3f} bits, I(BP;Y) = {I_bp_y:.3f} bits\")\n",
    "print(f\"I(HR,BP;Y) = {I_hrbp_y:.3f} bits\")\n",
    "print(f\"Redundancy = {I_red:.3f}, Unique(HR) = {U_hr:.3f}, Unique(BP) = {U_bp:.3f}, Synergy = {S:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DI (BP->HR) = 0.7871107149038481 bits\n"
     ]
    }
   ],
   "source": [
    "# Simulated timeline (simplified): 0=normal, 1=anomalous\n",
    "HR_flag_seq = [0, 0, 0, 0,  # baseline normal\n",
    "               0,          # t=4: BP drop starts (will reflect in BP_flag_seq)\n",
    "               0,          # HR normal until BP drops\n",
    "               0,          # \n",
    "               0]          # (extend as needed)\n",
    "BP_flag_seq = [0, 0, 0, 0, \n",
    "               1,          # t=4: BP_flag goes low (BP drop)\n",
    "               1,          # t=5: BP still low\n",
    "               1,          # t=6: BP low...\n",
    "               0]          # recovery\n",
    "\n",
    "# At t=5, HR responds to prior BP drop:\n",
    "HR_flag_seq[5] = 1          # t=5: HR_flag goes high in response to BP low at t=4\n",
    "\n",
    "# Calculate transfer entropy TE(BP -> HR)\n",
    "import math\n",
    "from collections import Counter\n",
    "triples = Counter()\n",
    "for t in range(1, len(HR_flag_seq)):\n",
    "    triples[(BP_flag_seq[t-1], HR_flag_seq[t-1], HR_flag_seq[t])] += 1\n",
    "\n",
    "# Compute joint and conditional probabilities\n",
    "total = sum(triples.values())\n",
    "TE_bp_to_hr = 0.0\n",
    "# Sum_{bp_prev, hr_prev, hr_curr} P(bp_prev, hr_prev, hr_curr) * log2[ P(hr_curr | bp_prev, hr_prev) / P(hr_curr | hr_prev) ]\n",
    "# (We derive conditional probabilities from frequency counts)\n",
    "from collections import defaultdict\n",
    "cond_counts = defaultdict(lambda: defaultdict(int))\n",
    "cond_counts_hr = defaultdict(lambda: defaultdict(int))\n",
    "for (bp_prev, hr_prev, hr_curr), count in triples.items():\n",
    "    cond_counts[(hr_prev, bp_prev)][hr_curr] += count\n",
    "    cond_counts_hr[hr_prev][hr_curr] += count\n",
    "\n",
    "for (hr_prev, bp_prev), outcomes in cond_counts.items():\n",
    "    for hr_curr, count in outcomes.items():\n",
    "        p_joint = count / total\n",
    "        p_hr_given_hr_bp = count / sum(outcomes.values())\n",
    "        p_hr_given_hr = count / sum(cond_counts_hr[hr_prev].values())\n",
    "        TE_bp_to_hr += p_joint * math.log2(p_hr_given_hr_bp / p_hr_given_hr)\n",
    "\n",
    "print(\"DI (BP->HR) =\", TE_bp_to_hr, \"bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dami",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
